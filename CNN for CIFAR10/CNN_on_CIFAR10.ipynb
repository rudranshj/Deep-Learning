{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN on CIFAR10.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztT00qu5gWqp"
      },
      "source": [
        "seed = 1\n",
        "\n",
        "import os\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
        "\n",
        "import random as rn\n",
        "rn.seed(seed)\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(seed)\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_zSa9Wr577A"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.datasets import cifar10\n",
        "from keras import regularizers\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "import numpy as np\n",
        "np.random.seed(seed)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "IrqOAVVcktkK",
        "outputId": "1238d35e-3f10-4ea2-c094-e45e83ea32de"
      },
      "source": [
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OD63RoNz6QUT"
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQi97bUbgfeu",
        "outputId": "9c8ca60f-470b-4d19-a1af-b1dd15aa4994"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print(\"train_images shape:\", x_train.shape)\n",
        "print(\"test_images shape:\", x_test.shape)\n",
        "print(\"train_labels shape:\", y_train.shape)\n",
        "print(\"test_labels shape:\", y_test.shape)\n",
        "\n",
        "# train_images = train_images / 255\n",
        "# test_images = test_images / 255"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_images shape: (50000, 32, 32, 3)\n",
            "test_images shape: (10000, 32, 32, 3)\n",
            "train_labels shape: (50000, 1)\n",
            "test_labels shape: (10000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubvqrO2Q6bmc"
      },
      "source": [
        "mean = np.mean(x_train,axis=(0,1,2,3))\n",
        "std = np.std(x_train,axis=(0,1,2,3))\n",
        "x_train = (x_train-mean)/(std+1e-7)\n",
        "x_test = (x_test-mean)/(std+1e-7)\n",
        " \n",
        "num_classes = 10\n",
        "y_train = np_utils.to_categorical(y_train,num_classes)\n",
        "y_test = np_utils.to_categorical(y_test,num_classes)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvbw4b2d6gO-"
      },
      "source": [
        "def lr_schedule(epoch):\n",
        "    lrate = 0.001\n",
        "    if epoch > 75:\n",
        "        lrate = 0.0005\n",
        "    if epoch > 100:\n",
        "        lrate = 0.0003\n",
        "    return lrate\n",
        "    \n",
        "weight_decay = 1e-4\n",
        "batch_size = 64"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGlcw9wxgyM-",
        "outputId": "c0928d98-80ea-4d60-8488-69c9771f5d0f"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.2))\n",
        " \n",
        "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.3))\n",
        " \n",
        "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
        "model.add(Activation('elu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.4))\n",
        " \n",
        "model.add(Flatten())\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        " \n",
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 8, 8, 128)         147584    \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 309,290\n",
            "Trainable params: 308,394\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WFaghPA7Ful"
      },
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    )\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCQVEppahIf_",
        "outputId": "970342c4-b740-4886-9e99-2941797ba6b0"
      },
      "source": [
        "num_epochs = 150\n",
        "opt_rms = keras.optimizers.RMSprop(learning_rate=0.001,decay=1e-6)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt_rms, metrics=['accuracy'])\n",
        "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                    steps_per_epoch=x_train.shape[0] // batch_size, epochs = num_epochs,\n",
        "                    verbose=1, validation_data=(x_test,y_test), callbacks=[LearningRateScheduler(lr_schedule)])\n",
        "#save to disk\n",
        "# model_json = model.to_json()\n",
        "# with open('model.json', 'w') as json_file:\n",
        "#     json_file.write(model_json)\n",
        "# model.save_weights('model.h5') \n",
        " \n",
        "#testing\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1915: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "781/781 [==============================] - 29s 34ms/step - loss: 0.7497 - accuracy: 0.7802 - val_loss: 0.6834 - val_accuracy: 0.8127\n",
            "Epoch 2/150\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.7291 - accuracy: 0.7875 - val_loss: 0.7254 - val_accuracy: 0.8038\n",
            "Epoch 3/150\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.7124 - accuracy: 0.7979 - val_loss: 0.6641 - val_accuracy: 0.8160\n",
            "Epoch 4/150\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.6991 - accuracy: 0.8014 - val_loss: 0.6791 - val_accuracy: 0.8217\n",
            "Epoch 5/150\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.6938 - accuracy: 0.8053 - val_loss: 0.6404 - val_accuracy: 0.8271\n",
            "Epoch 6/150\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.6912 - accuracy: 0.8055 - val_loss: 0.6295 - val_accuracy: 0.8333\n",
            "Epoch 7/150\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.6823 - accuracy: 0.8083 - val_loss: 0.6747 - val_accuracy: 0.8289\n",
            "Epoch 8/150\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.6708 - accuracy: 0.8142 - val_loss: 0.6574 - val_accuracy: 0.8254\n",
            "Epoch 9/150\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.6658 - accuracy: 0.8173 - val_loss: 0.7391 - val_accuracy: 0.8048\n",
            "Epoch 10/150\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.6569 - accuracy: 0.8207 - val_loss: 0.6684 - val_accuracy: 0.8242\n",
            "Epoch 11/150\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.6580 - accuracy: 0.8209 - val_loss: 0.6354 - val_accuracy: 0.8314\n",
            "Epoch 12/150\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.6478 - accuracy: 0.8248 - val_loss: 0.6839 - val_accuracy: 0.8171\n",
            "Epoch 13/150\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.6471 - accuracy: 0.8237 - val_loss: 0.7106 - val_accuracy: 0.8165\n",
            "Epoch 14/150\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.6418 - accuracy: 0.8283 - val_loss: 0.6510 - val_accuracy: 0.8379\n",
            "Epoch 15/150\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.6351 - accuracy: 0.8298 - val_loss: 0.6355 - val_accuracy: 0.8374\n",
            "Epoch 16/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.6413 - accuracy: 0.8290 - val_loss: 0.6137 - val_accuracy: 0.8421\n",
            "Epoch 17/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.6332 - accuracy: 0.8340 - val_loss: 0.6404 - val_accuracy: 0.8354\n",
            "Epoch 18/150\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.6417 - accuracy: 0.8301 - val_loss: 0.5786 - val_accuracy: 0.8541\n",
            "Epoch 19/150\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.6402 - accuracy: 0.8287 - val_loss: 0.6006 - val_accuracy: 0.8478\n",
            "Epoch 20/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.6295 - accuracy: 0.8334 - val_loss: 0.6579 - val_accuracy: 0.8345\n",
            "Epoch 21/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.6299 - accuracy: 0.8325 - val_loss: 0.6187 - val_accuracy: 0.8450\n",
            "Epoch 22/150\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.6296 - accuracy: 0.8336 - val_loss: 0.6425 - val_accuracy: 0.8362\n",
            "Epoch 23/150\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.6225 - accuracy: 0.8348 - val_loss: 0.7051 - val_accuracy: 0.8190\n",
            "Epoch 24/150\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.6263 - accuracy: 0.8365 - val_loss: 0.5819 - val_accuracy: 0.8558\n",
            "Epoch 25/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.6172 - accuracy: 0.8378 - val_loss: 0.6071 - val_accuracy: 0.8477\n",
            "Epoch 26/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.6166 - accuracy: 0.8363 - val_loss: 0.6291 - val_accuracy: 0.8444\n",
            "Epoch 27/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.6162 - accuracy: 0.8389 - val_loss: 0.6321 - val_accuracy: 0.8403\n",
            "Epoch 28/150\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.6080 - accuracy: 0.8427 - val_loss: 0.6422 - val_accuracy: 0.8383\n",
            "Epoch 29/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.6128 - accuracy: 0.8371 - val_loss: 0.6555 - val_accuracy: 0.8372\n",
            "Epoch 30/150\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.6066 - accuracy: 0.8410 - val_loss: 0.6069 - val_accuracy: 0.8482\n",
            "Epoch 31/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.6025 - accuracy: 0.8447 - val_loss: 0.5955 - val_accuracy: 0.8483\n",
            "Epoch 32/150\n",
            "781/781 [==============================] - 28s 35ms/step - loss: 0.6042 - accuracy: 0.8455 - val_loss: 0.6669 - val_accuracy: 0.8288\n",
            "Epoch 33/150\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.6099 - accuracy: 0.8421 - val_loss: 0.6377 - val_accuracy: 0.8435\n",
            "Epoch 34/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.6035 - accuracy: 0.8422 - val_loss: 0.6641 - val_accuracy: 0.8338\n",
            "Epoch 35/150\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.6028 - accuracy: 0.8448 - val_loss: 0.6005 - val_accuracy: 0.8513\n",
            "Epoch 36/150\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5966 - accuracy: 0.8479 - val_loss: 0.5571 - val_accuracy: 0.8654\n",
            "Epoch 37/150\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5976 - accuracy: 0.8474 - val_loss: 0.5931 - val_accuracy: 0.8557\n",
            "Epoch 38/150\n",
            "781/781 [==============================] - 25s 32ms/step - loss: 0.6054 - accuracy: 0.8441 - val_loss: 0.5841 - val_accuracy: 0.8574\n",
            "Epoch 39/150\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.6040 - accuracy: 0.8431 - val_loss: 0.5933 - val_accuracy: 0.8541\n",
            "Epoch 40/150\n",
            "781/781 [==============================] - 25s 33ms/step - loss: 0.5965 - accuracy: 0.8466 - val_loss: 0.5904 - val_accuracy: 0.8535\n",
            "Epoch 41/150\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5951 - accuracy: 0.8473 - val_loss: 0.6552 - val_accuracy: 0.8304\n",
            "Epoch 42/150\n",
            "781/781 [==============================] - 25s 33ms/step - loss: 0.5952 - accuracy: 0.8482 - val_loss: 0.5638 - val_accuracy: 0.8629\n",
            "Epoch 43/150\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5853 - accuracy: 0.8495 - val_loss: 0.5932 - val_accuracy: 0.8590\n",
            "Epoch 44/150\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5884 - accuracy: 0.8499 - val_loss: 0.5975 - val_accuracy: 0.8520\n",
            "Epoch 45/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.5938 - accuracy: 0.8465 - val_loss: 0.6326 - val_accuracy: 0.8459\n",
            "Epoch 46/150\n",
            "781/781 [==============================] - 28s 35ms/step - loss: 0.5852 - accuracy: 0.8515 - val_loss: 0.6036 - val_accuracy: 0.8500\n",
            "Epoch 47/150\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5868 - accuracy: 0.8497 - val_loss: 0.6471 - val_accuracy: 0.8371\n",
            "Epoch 48/150\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5890 - accuracy: 0.8497 - val_loss: 0.6413 - val_accuracy: 0.8440\n",
            "Epoch 49/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.5886 - accuracy: 0.8500 - val_loss: 0.6207 - val_accuracy: 0.8474\n",
            "Epoch 50/150\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5912 - accuracy: 0.8502 - val_loss: 0.5964 - val_accuracy: 0.8520\n",
            "Epoch 51/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.5869 - accuracy: 0.8530 - val_loss: 0.5725 - val_accuracy: 0.8621\n",
            "Epoch 52/150\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5826 - accuracy: 0.8524 - val_loss: 0.5788 - val_accuracy: 0.8571\n",
            "Epoch 53/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.5836 - accuracy: 0.8517 - val_loss: 0.5986 - val_accuracy: 0.8501\n",
            "Epoch 54/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.5894 - accuracy: 0.8487 - val_loss: 0.5885 - val_accuracy: 0.8534\n",
            "Epoch 55/150\n",
            "781/781 [==============================] - 28s 35ms/step - loss: 0.5793 - accuracy: 0.8528 - val_loss: 0.5998 - val_accuracy: 0.8515\n",
            "Epoch 56/150\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.5733 - accuracy: 0.8567 - val_loss: 0.6627 - val_accuracy: 0.8400\n",
            "Epoch 57/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.5784 - accuracy: 0.8551 - val_loss: 0.6238 - val_accuracy: 0.8479\n",
            "Epoch 58/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.5833 - accuracy: 0.8497 - val_loss: 0.6002 - val_accuracy: 0.8531\n",
            "Epoch 59/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.5839 - accuracy: 0.8548 - val_loss: 0.5839 - val_accuracy: 0.8632\n",
            "Epoch 60/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.5750 - accuracy: 0.8565 - val_loss: 0.5641 - val_accuracy: 0.8689\n",
            "Epoch 61/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.5758 - accuracy: 0.8544 - val_loss: 0.6108 - val_accuracy: 0.8549\n",
            "Epoch 62/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.5745 - accuracy: 0.8561 - val_loss: 0.6187 - val_accuracy: 0.8506\n",
            "Epoch 63/150\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.5782 - accuracy: 0.8544 - val_loss: 0.6146 - val_accuracy: 0.8477\n",
            "Epoch 64/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.5660 - accuracy: 0.8574 - val_loss: 0.6067 - val_accuracy: 0.8528\n",
            "Epoch 65/150\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.5788 - accuracy: 0.8547 - val_loss: 0.5676 - val_accuracy: 0.8612\n",
            "Epoch 66/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.5688 - accuracy: 0.8567 - val_loss: 0.6717 - val_accuracy: 0.8335\n",
            "Epoch 67/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.5696 - accuracy: 0.8551 - val_loss: 0.6289 - val_accuracy: 0.8457\n",
            "Epoch 68/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.5721 - accuracy: 0.8575 - val_loss: 0.5552 - val_accuracy: 0.8668\n",
            "Epoch 69/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.5679 - accuracy: 0.8588 - val_loss: 0.5746 - val_accuracy: 0.8650\n",
            "Epoch 70/150\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5682 - accuracy: 0.8576 - val_loss: 0.7088 - val_accuracy: 0.8316\n",
            "Epoch 71/150\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.5690 - accuracy: 0.8594 - val_loss: 0.6115 - val_accuracy: 0.8542\n",
            "Epoch 72/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.5649 - accuracy: 0.8569 - val_loss: 0.6375 - val_accuracy: 0.8444\n",
            "Epoch 73/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.5672 - accuracy: 0.8588 - val_loss: 0.6161 - val_accuracy: 0.8544\n",
            "Epoch 74/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.5600 - accuracy: 0.8583 - val_loss: 0.5795 - val_accuracy: 0.8621\n",
            "Epoch 75/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.5658 - accuracy: 0.8580 - val_loss: 0.5767 - val_accuracy: 0.8651\n",
            "Epoch 76/150\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.5722 - accuracy: 0.8571 - val_loss: 0.5850 - val_accuracy: 0.8632\n",
            "Epoch 77/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.5287 - accuracy: 0.8711 - val_loss: 0.5412 - val_accuracy: 0.8735\n",
            "Epoch 78/150\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.5097 - accuracy: 0.8751 - val_loss: 0.5262 - val_accuracy: 0.8755\n",
            "Epoch 79/150\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.5049 - accuracy: 0.8772 - val_loss: 0.5050 - val_accuracy: 0.8833\n",
            "Epoch 80/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.4921 - accuracy: 0.8793 - val_loss: 0.5040 - val_accuracy: 0.8803\n",
            "Epoch 81/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.4817 - accuracy: 0.8837 - val_loss: 0.5013 - val_accuracy: 0.8784\n",
            "Epoch 82/150\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4870 - accuracy: 0.8787 - val_loss: 0.5347 - val_accuracy: 0.8741\n",
            "Epoch 83/150\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4807 - accuracy: 0.8813 - val_loss: 0.5375 - val_accuracy: 0.8717\n",
            "Epoch 84/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.4778 - accuracy: 0.8822 - val_loss: 0.5284 - val_accuracy: 0.8741\n",
            "Epoch 85/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.4702 - accuracy: 0.8825 - val_loss: 0.5150 - val_accuracy: 0.8765\n",
            "Epoch 86/150\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4735 - accuracy: 0.8791 - val_loss: 0.5118 - val_accuracy: 0.8801\n",
            "Epoch 87/150\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4599 - accuracy: 0.8855 - val_loss: 0.4893 - val_accuracy: 0.8824\n",
            "Epoch 88/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.4674 - accuracy: 0.8842 - val_loss: 0.5074 - val_accuracy: 0.8794\n",
            "Epoch 89/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.4612 - accuracy: 0.8822 - val_loss: 0.5139 - val_accuracy: 0.8768\n",
            "Epoch 90/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.4618 - accuracy: 0.8857 - val_loss: 0.5110 - val_accuracy: 0.8770\n",
            "Epoch 91/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.4585 - accuracy: 0.8862 - val_loss: 0.5238 - val_accuracy: 0.8745\n",
            "Epoch 92/150\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4596 - accuracy: 0.8836 - val_loss: 0.5197 - val_accuracy: 0.8744\n",
            "Epoch 93/150\n",
            "781/781 [==============================] - 26s 33ms/step - loss: 0.4621 - accuracy: 0.8828 - val_loss: 0.4737 - val_accuracy: 0.8899\n",
            "Epoch 94/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.4572 - accuracy: 0.8832 - val_loss: 0.5000 - val_accuracy: 0.8776\n",
            "Epoch 95/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.4498 - accuracy: 0.8856 - val_loss: 0.4947 - val_accuracy: 0.8824\n",
            "Epoch 96/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.4530 - accuracy: 0.8843 - val_loss: 0.4938 - val_accuracy: 0.8814\n",
            "Epoch 97/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.4529 - accuracy: 0.8827 - val_loss: 0.4835 - val_accuracy: 0.8850\n",
            "Epoch 98/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.4550 - accuracy: 0.8832 - val_loss: 0.4926 - val_accuracy: 0.8804\n",
            "Epoch 99/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.4519 - accuracy: 0.8848 - val_loss: 0.4554 - val_accuracy: 0.8918\n",
            "Epoch 100/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.4518 - accuracy: 0.8859 - val_loss: 0.4957 - val_accuracy: 0.8787\n",
            "Epoch 101/150\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4456 - accuracy: 0.8857 - val_loss: 0.4831 - val_accuracy: 0.8796\n",
            "Epoch 102/150\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.4380 - accuracy: 0.8880 - val_loss: 0.5053 - val_accuracy: 0.8786\n",
            "Epoch 103/150\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4188 - accuracy: 0.8947 - val_loss: 0.4781 - val_accuracy: 0.8844\n",
            "Epoch 104/150\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4209 - accuracy: 0.8919 - val_loss: 0.4644 - val_accuracy: 0.8913\n",
            "Epoch 105/150\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.4197 - accuracy: 0.8935 - val_loss: 0.4546 - val_accuracy: 0.8906\n",
            "Epoch 106/150\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4166 - accuracy: 0.8949 - val_loss: 0.4820 - val_accuracy: 0.8852\n",
            "Epoch 107/150\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.4146 - accuracy: 0.8945 - val_loss: 0.5028 - val_accuracy: 0.8802\n",
            "Epoch 108/150\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4098 - accuracy: 0.8959 - val_loss: 0.4500 - val_accuracy: 0.8895\n",
            "Epoch 109/150\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.4054 - accuracy: 0.8961 - val_loss: 0.4611 - val_accuracy: 0.8877\n",
            "Epoch 110/150\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4034 - accuracy: 0.8955 - val_loss: 0.4853 - val_accuracy: 0.8838\n",
            "Epoch 111/150\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.4045 - accuracy: 0.8965 - val_loss: 0.5507 - val_accuracy: 0.8660\n",
            "Epoch 112/150\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.3998 - accuracy: 0.8963 - val_loss: 0.4939 - val_accuracy: 0.8828\n",
            "Epoch 113/150\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.3992 - accuracy: 0.8986 - val_loss: 0.4776 - val_accuracy: 0.8843\n",
            "Epoch 114/150\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.4026 - accuracy: 0.8973 - val_loss: 0.4717 - val_accuracy: 0.8848\n",
            "Epoch 115/150\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.4062 - accuracy: 0.8959 - val_loss: 0.4679 - val_accuracy: 0.8862\n",
            "Epoch 116/150\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.3976 - accuracy: 0.8972 - val_loss: 0.4476 - val_accuracy: 0.8914\n",
            "Epoch 117/150\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.4028 - accuracy: 0.8984 - val_loss: 0.4441 - val_accuracy: 0.8927\n",
            "Epoch 118/150\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.3966 - accuracy: 0.8970 - val_loss: 0.4663 - val_accuracy: 0.8883\n",
            "Epoch 119/150\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.3965 - accuracy: 0.8968 - val_loss: 0.4429 - val_accuracy: 0.8917\n",
            "Epoch 120/150\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.3959 - accuracy: 0.8977 - val_loss: 0.4543 - val_accuracy: 0.8894\n",
            "Epoch 121/150\n",
            "781/781 [==============================] - 27s 35ms/step - loss: 0.3893 - accuracy: 0.8995 - val_loss: 0.4907 - val_accuracy: 0.8794\n",
            "Epoch 122/150\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.3920 - accuracy: 0.9000 - val_loss: 0.4364 - val_accuracy: 0.8946\n",
            "Epoch 123/150\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.3962 - accuracy: 0.8954 - val_loss: 0.4482 - val_accuracy: 0.8891\n",
            "Epoch 124/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.3852 - accuracy: 0.9007 - val_loss: 0.4302 - val_accuracy: 0.8949\n",
            "Epoch 125/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.3885 - accuracy: 0.8984 - val_loss: 0.4530 - val_accuracy: 0.8867\n",
            "Epoch 126/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.3927 - accuracy: 0.8981 - val_loss: 0.4636 - val_accuracy: 0.8845\n",
            "Epoch 127/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.3872 - accuracy: 0.9002 - val_loss: 0.4303 - val_accuracy: 0.8908\n",
            "Epoch 128/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.3760 - accuracy: 0.9008 - val_loss: 0.4634 - val_accuracy: 0.8835\n",
            "Epoch 129/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.3886 - accuracy: 0.8988 - val_loss: 0.4454 - val_accuracy: 0.8873\n",
            "Epoch 130/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.3898 - accuracy: 0.8986 - val_loss: 0.4582 - val_accuracy: 0.8847\n",
            "Epoch 131/150\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.3909 - accuracy: 0.8948 - val_loss: 0.4450 - val_accuracy: 0.8907\n",
            "Epoch 132/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.3802 - accuracy: 0.9003 - val_loss: 0.4655 - val_accuracy: 0.8846\n",
            "Epoch 133/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.3852 - accuracy: 0.9016 - val_loss: 0.4449 - val_accuracy: 0.8893\n",
            "Epoch 134/150\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.3818 - accuracy: 0.8994 - val_loss: 0.4572 - val_accuracy: 0.8853\n",
            "Epoch 135/150\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.3849 - accuracy: 0.8982 - val_loss: 0.4902 - val_accuracy: 0.8779\n",
            "Epoch 136/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.3894 - accuracy: 0.8988 - val_loss: 0.4459 - val_accuracy: 0.8919\n",
            "Epoch 137/150\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.3775 - accuracy: 0.9016 - val_loss: 0.4362 - val_accuracy: 0.8923\n",
            "Epoch 138/150\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.3802 - accuracy: 0.9010 - val_loss: 0.4615 - val_accuracy: 0.8867\n",
            "Epoch 139/150\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.3794 - accuracy: 0.9001 - val_loss: 0.4386 - val_accuracy: 0.8923\n",
            "Epoch 140/150\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.3820 - accuracy: 0.8992 - val_loss: 0.4317 - val_accuracy: 0.8938\n",
            "Epoch 141/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.3753 - accuracy: 0.9026 - val_loss: 0.4559 - val_accuracy: 0.8858\n",
            "Epoch 142/150\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.3790 - accuracy: 0.9003 - val_loss: 0.4490 - val_accuracy: 0.8913\n",
            "Epoch 143/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.3797 - accuracy: 0.9005 - val_loss: 0.4840 - val_accuracy: 0.8785\n",
            "Epoch 144/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.3772 - accuracy: 0.9005 - val_loss: 0.4561 - val_accuracy: 0.8850\n",
            "Epoch 145/150\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.3817 - accuracy: 0.9008 - val_loss: 0.4340 - val_accuracy: 0.8921\n",
            "Epoch 146/150\n",
            "781/781 [==============================] - 27s 34ms/step - loss: 0.3770 - accuracy: 0.9012 - val_loss: 0.4604 - val_accuracy: 0.8855\n",
            "Epoch 147/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.3739 - accuracy: 0.9012 - val_loss: 0.4761 - val_accuracy: 0.8815\n",
            "Epoch 148/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.3780 - accuracy: 0.9020 - val_loss: 0.4528 - val_accuracy: 0.8849\n",
            "Epoch 149/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.3817 - accuracy: 0.8977 - val_loss: 0.4667 - val_accuracy: 0.8826\n",
            "Epoch 150/150\n",
            "781/781 [==============================] - 26s 34ms/step - loss: 0.3678 - accuracy: 0.9031 - val_loss: 0.4308 - val_accuracy: 0.8914\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1c86f02b90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oh-ulhKAhSJb"
      },
      "source": [
        ""
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52rj3fi8hhWK"
      },
      "source": [
        ""
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FzT-O_9hskR",
        "outputId": "11a858ab-ec46-4a3e-9e8f-67c61e0ee847"
      },
      "source": [
        "scores = model.evaluate(x_train, y_train, batch_size=128, verbose=1)\n",
        "print('\\nTest result: %.3f loss: %.3f' % (scores[1]*100,scores[0]))\n",
        "\n",
        "scores = model.evaluate(x_test, y_test, batch_size=128, verbose=1)\n",
        "print('\\nTest result: %.3f loss: %.3f' % (scores[1]*100,scores[0]))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 3s 7ms/step - loss: 0.2573 - accuracy: 0.9450\n",
            "\n",
            "Test result: 94.498 loss: 0.257\n",
            "79/79 [==============================] - 1s 6ms/step - loss: 0.4308 - accuracy: 0.8914\n",
            "\n",
            "Test result: 89.140 loss: 0.431\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuvZp1m7hwq5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}